{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c83393-e064-4b03-8053-4e0ccd29d7fb",
   "metadata": {},
   "source": [
    "## openai_generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b6f5916-e18a-4e67-af11-17dca8a3084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd4ce825-6e8a-4c86-a238-bd2c7c95a8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openai_generate_text(api_key, prompt, context=None, model=\"gpt-4\", temperature=0.7, max_tokens=100, stop=None):\n",
    "    \"\"\"\n",
    "    Generates text based on a given prompt using the OpenAI API.\n",
    "\n",
    "    Parameters:\n",
    "    api_key (str): The API key for accessing the OpenAI API.\n",
    "    prompt (str): The prompt to generate text from.\n",
    "    context (str): Optional context to provide additional information for the text generation.\n",
    "    model (str): The model to use for text generation (default is \"gpt-4\").\n",
    "    temperature (float): Sampling temperature to control the creativity of the model (default is 0.7).\n",
    "    max_tokens (int): The maximum number of tokens in the generated text (default is 100).\n",
    "    stop (str or list): Optional stop sequence to end the generation.\n",
    "\n",
    "    Returns:\n",
    "    str: Text generated by the OpenAI API.\n",
    "    \"\"\"\n",
    "    if context:\n",
    "        prompt_content = f\"Context: {context}\\n\\nPrompt: {prompt}\"\n",
    "    else:\n",
    "        prompt_content = f\"Prompt: {prompt}\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt_content}\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stop\": stop\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, data=json.dumps(data))\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        generated_text = response_json[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "        return generated_text\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3ac5b4-4864-40be-ae7f-319efa9a3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Once upon a time in a land far, far away, there was a little village surrounded by mountains.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd8d5697-b9df-4dd6-acf1-bf3d09774086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text: This quaint hamlet was known as Edelweiss, named after the delicate white flower that thrived along the rocky slopes of the mountains. A river, as clear as crystal, flowed through the heart of the village, providing nourishment to the lush vegetation and wildlife in the area. The houses were made of stone and wood, with blooming flower boxes hanging from the windows and smoke spiraling gently from their chimneys.\n"
     ]
    }
   ],
   "source": [
    "generated_text = openai_generate_text(api_key, prompt, temperature=0.8, max_tokens=150, stop=[\"\\n\"])\n",
    "print(\"Generated Text:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e222e9ae-2b48-4140-bb50-8aed3b73fd54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
